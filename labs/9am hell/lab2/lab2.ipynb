{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Clustering\n",
    "In this lab we look at clustering with k-means and GMMs. We will work on putting together the skeleton code to create the functionality of the algorithms, and then we will cluster the Fisher Iris dataset. We will finish by looking at the sklearn implementations of these algorithms.\n",
    "\n",
    "<b>Important note:</b> \n",
    "    Please do not edit the existing code snippets. Instead, add your functionality into the TODO sections. Read the entire skeleton structure first and think about how you should structure the code you are adding in carefully.\n",
    "    \n",
    "There are <b>42</b> TODOs in this lab. It may seem like a lot but don't worry. Many are just selecting hyper-parameters and many of the visualisation TODOs are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1 - Data Exploration\n",
    "This task will load the data and explore the feature space of the observations. We will plot two feature dimensions against eachother, labeling them based on colour from the known class IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do your package imports here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the data and the labels from file.\n",
    "# TODO: Plot two feature dimensions against eachother, labeling the axes accordingly.\n",
    "# TODO: Make sure the markers in the plot are coloured with their respective class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2 - K-means Clustering \n",
    "The task here is to fill out the skeleton code in order to complete the k-means implementation. Follow the lecture notes and take some hints along the way. We first define a function to calculate the Euclidean distance between each of the cluster centres and the data, then we initialise our hyper-parameters and create a loop to fit our clusters to the data.\n",
    "\n",
    "### K-Means algorithm:\n",
    "\n",
    "Setup: Select random initial set of k cluster centers\n",
    "\n",
    "Loop:\n",
    "\n",
    "    for i = 1 to maximum number of iterations\n",
    "        calculate distance from training points to cluster centroids\n",
    "        update class labels\n",
    "        recalculate centroid locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of euclidean distance function between cluster centroid and matrix of datapoints\n",
    "def euclidean_distance(k_centroids, datapoints):\n",
    "    dists = np.zeros(shape=[datapoints.shape[0], k_centroids.shape[0]])\n",
    "    \n",
    "    for iK in range(0, k_centroids.shape[0]):\n",
    "        centre = np.tile(k_centroids[iK, :], (datapoints.shape[0], 1))\n",
    "        diff = centre - datapoints\n",
    "        sum_of_squared_differences = np.zeros([datapoints.shape[0]])\n",
    "        for i_dimension in range(0, k_centroids.shape[1]):\n",
    "            sum_of_squared_differences += (diff[:, i_dimension]**2)\n",
    "        dists[:,iK] = np.sqrt(sum_of_squared_differences)\n",
    "        \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = # TODO: Select a number of clusters.\n",
    "n_iteration = # TODO: Select a number of iterations.\n",
    "k_centroid = # TODO: Select cluster centroids.\n",
    "\n",
    "for # TODO: Loop over each iteration.\n",
    "    last_k_centroid = k_centroid\n",
    "    \n",
    "    #Calculate distances\n",
    "    dists = euclidean_distance(k_centroid, data)\n",
    "        \n",
    "    #Reassign labels\n",
    "    predicted_label = # TODO: Get cluster label based on distance from centroid. Hint: argmin.\n",
    "    \n",
    "    #Recalculate centroids\n",
    "    new_centroid = np.zeros(shape=[k,data.shape[1]])\n",
    "    for # TODO: Loop over each cluster iK.\n",
    "        #Get all datapoints alocated to cluster iK\n",
    "        cluster_data = # TODO: Slice into data with predicted_label.\n",
    "        #Calculate the mean of this cluster\n",
    "        new_centroid[iK, :] = # TODO: Calculate mean of datapoints.\n",
    "        \n",
    "    #Assign the new cluster centers\n",
    "    k_centroid = new_centroid\n",
    "        \n",
    "    print('Iteration {0}: total update distance of centroids: {1}'.format(i, np.sum(np.abs(new_centroid - last_k_centroid))))\n",
    "    \n",
    "#Visualisation of model predictions\n",
    "# TODO: Plot two feature dimensions against eachother, label with the predicted cluster labels.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('Our implementation of k-Means')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3 - Gaussian Mixture Models\n",
    "The task here is to fill out the skeleton code in order to complete the GMM implementation. Follow the lecture notes and take some hints along the way. We first define some functions for the algorithm, followed by initialisation of the parameters, and finally we implement the loop within which we fit our Gaussians to our data.\n",
    "\n",
    "### GMM Algorithm:\n",
    "Setup: Initialise Gaussian distribution centroid, standard deviations and mixing coefficients using k-means coefficients.\n",
    "\n",
    "Loop: \n",
    "\n",
    "    Compute E-Step: calculate posteriors for the data given current Gaussian parameters \n",
    "    Compute M-Step: update model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out which one is the E-Step and which is the M-Step.\n",
    "\n",
    "def multivariate_gaussian_density(x, mu, sig):\n",
    "    size = x.shape[0]\n",
    "    det = np.linalg.det(sig)\n",
    "    norm_const = 1.0 / ((2*np.pi)**(size/2) * det **(1.0/2) )\n",
    "    x_mu = x - mu\n",
    "    inv = np.linalg.inv(sig)  \n",
    "    result = np.e**(-(1.0/2) * (x_mu @ inv @ x_mu.T))\n",
    "    \n",
    "    return norm_const * result\n",
    "    \n",
    "    \n",
    "def likelihood(x,gCentroids, gSD, gMix):\n",
    "    p = np.zeros([x.shape[0],gCentroids.shape[0]])\n",
    "    p_total = np.zeros(x.shape[0])\n",
    "    posteriors = np.zeros([x.shape[0],gCentroids.shape[0]])\n",
    "    \n",
    "    for iSample in range(0, x.shape[0]):\n",
    "        for iCluster in range(0, gCentroids.shape[0]):\n",
    "            p[iSample,iCluster] = multivariate_gaussian_density(x[iSample,:].T, gCentroids[iCluster,:], gSD[:,:,iCluster])\n",
    "            p_total[iSample] = p_total[iSample] + p[iSample,iCluster] \n",
    "        \n",
    "        for iCluster in range(0, gCentroids.shape[0]):\n",
    "            posteriors[iSample, iCluster] = p[iSample, iCluster] / p_total[iSample]\n",
    "            \n",
    "    return posteriors    \n",
    "\n",
    "\n",
    "def update_params(data, posteriors, gMix, gSD, gCentroids):\n",
    "    #Update mixing coefs\n",
    "    newGMix = # TODO: Use the equation on lab sheet to calculate the new mixing coefficients.\n",
    "    \n",
    "    \n",
    "    #Update centroids\n",
    "    newCentroids = np.zeros(gCentroids.shape)\n",
    "    for iCluster in range(0, gMix.shape[0]):\n",
    "        norm = np.expand_dims(posteriors[:, iCluster],axis=1)/np.sum(posteriors[:,iCluster])\n",
    "        newCentroids[iCluster, :] = np.sum(norm * data, axis=0)\n",
    "\n",
    "    #Update covariance matrices\n",
    "    newGSD = np.zeros(gSD.shape)\n",
    "    for c in range(0, gMix.shape[0]):\n",
    "        running_sum = np.zeros(gSD.shape[0:2]) \n",
    "        for iData in range(0, data.shape[0]):\n",
    "            mean_centred_data = (np.expand_dims(data[iData, :],axis=0) - newCentroids[c,:])\n",
    "            running_sum += posteriors[iData, iCluster] * mean_centred_data * mean_centred_data.T\n",
    "        running_sum = running_sum / np.sum(posteriors[:,iCluster],axis=0)\n",
    "        newGSD[:,:,c] = running_sum\n",
    "\n",
    "    return newGMix, newGSD, newCentroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise parameters\n",
    "Initialise the number of components, the number of iterations and the Gaussian parameters (mus, sigmas, mixings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = # TODO: Select a number of Gaussians. Use the same number as k in task 2.2.\n",
    "nIteration = # TODO: Select a number of iterations.\n",
    "\n",
    "cluster_centroids = np.zeros([g,data.shape[1]])\n",
    "g_SD = np.zeros([data.shape[1],data.shape[1], g])\n",
    "g_mix = np.zeros(g)\n",
    "\n",
    "# TODO: Understand what is happening here. Hint: clustering part 2 lecture, slide 10.\n",
    "for iCluster in range(0,g):\n",
    "    data_in_cluster = data[predicted_label == iCluster, :]\n",
    "    cluster_centroids[iCluster,:] = np.mean(data_in_cluster, axis=0)\n",
    "    g_SD[:,:,iCluster] = np.cov(data_in_cluster.T)\n",
    "    g_mix[iCluster] = data_in_cluster.shape[0] / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop of GMM fitting\n",
    "Loop over our iterations, computing steps E and M repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, nIteration):\n",
    "    #E-Step\n",
    "    posteriors = # TODO: Call E-Step function.\n",
    "\n",
    "    #M-Step\n",
    "    g_mix, g_SD, cluster_centroids = # TODO: Call M-Step function.\n",
    "    \n",
    "    print('Iteration {0}'.format(i), end='\\r')\n",
    "    \n",
    "    \n",
    "\n",
    "#Predict labels\n",
    "predicted_label = # TODO: Get cluster label based on posterior. Hint: argmin.\n",
    "    \n",
    "#Visualisation of model predictions\n",
    "# TODO: Plot two feature dimensions against eachother, label with the predicted cluster labels.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('Our implementation of GMMs')\n",
    "plt.show()  \n",
    "\n",
    "#Visualisation of model posteriors\n",
    "# TODO: Create a new figure with plt.figure()\n",
    "# TODO: Plot two feature dimensions against eachother, label with the posteriors for a specific cluster.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('Posteriors of our GMM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SciKit-Learn\n",
    "Here we will import SciKit-Learn and use the built-in API functionality to run k-Means clustering and GMM on the Fisher Iris data.\n",
    "\n",
    "Here we can use the <b>sklearn.cluster.KMeans</b> object. We need to define a number of clusters and then call the <b>fit</b> and <b>predict</b> methods.\n",
    "\n",
    "We can also use the <b>sklearn.mixture.GaussianMixture</b> object. We need to define a number of Guassians and then call the <b>fit</b> and <b>predict</b> methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "import sklearn.mixture\n",
    "\n",
    "# TODO: Create an instance of an sklearn.cluster KMeans object with k clusters\n",
    "# TODO: Fit our data to the model with .fit(data)\n",
    "# TODO: Predict data clusters with .predict(data)\n",
    "# TODO: Plot two feature dimensions against eachother, label with the predicted cluster labels.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('sklearn implementation of GMMs')\n",
    "plt.show() \n",
    "\n",
    "\n",
    "# TODO: create an instance of an sklearn.mixture GaussianMixture object with g clusters\n",
    "# TODO: fit our data to the model with .fit(data)\n",
    "# TODO: predict data clusters with .predict(data)\n",
    "# TODO: Plot two feature dimensions against eachother, label with the predicted cluster labels.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('sklearn implementation of GMMs')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
